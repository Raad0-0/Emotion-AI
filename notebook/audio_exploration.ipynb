{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c2db5d",
   "metadata": {},
   "source": [
    "#Generate_label.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18dc3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file banaise\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "audio_dir = 'C:/Users/raada/Documents/Pray&Hope/data/audio'\n",
    "# print(f'audio_dir: {audio_dir}')\n",
    "\n",
    "emotion_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised',\n",
    "}\n",
    "\n",
    "data = []\n",
    "\n",
    "for root, dirs, files in os.walk(audio_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            parts = file.split('-')\n",
    "            emotion_code = parts [2]\n",
    "            emotion = emotion_map.get(emotion_code, 'unknown')\n",
    "            #Store the  relative path from data/audio\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), audio_dir)\n",
    "            data.append({'filename': relative_path, 'emotion': emotion})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df.to_csv(os.path.join(audio_dir, 'labels.csv'), index=False)\n",
    "\n",
    "print(\"file banaise\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73e955",
   "metadata": {},
   "source": [
    "#preprocessor_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab810594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# path to the audio directory and labels file\n",
    "audio_dir = 'C:/Users/raada/Documents/Pray&Hope/data/audio'\n",
    "labels_df = pd.read_csv(os.path.join(audio_dir, 'labels.csv'))\n",
    "\n",
    "#initialize lists to hold features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# loop through each row in the labels DataFrame\n",
    "for index, row in labels_df.iterrows():\n",
    "    audio_file = os.path.join(audio_dir, row['filename'])\n",
    "    emotion = row['emotion']\n",
    "\n",
    "    #load the audio file and standardize it\n",
    "    y, sr = librosa.load(audio_file, sr=16000) #resample to 16KHz\n",
    "    y = librosa.util.normalize(y)  # normalize the audio signal\n",
    "\n",
    "    # extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "    features.append(mfccs_mean)\n",
    "    labels.append(emotion)\n",
    "\n",
    "#conver to numpy arrays\n",
    "X = np.array(features)\n",
    "y =np.array(labels)\n",
    "\n",
    "np.save(os.path.join(audio_dir, 'x.npy'), X)\n",
    "np.save(os.path.join(audio_dir, 'y.npy'), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbdf6f4",
   "metadata": {},
   "source": [
    "#train_audio_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96698a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.74      0.60      0.66        42\n",
      "        calm       0.59      0.75      0.66        44\n",
      "     disgust       0.38      0.50      0.43        32\n",
      "     fearful       0.47      0.62      0.53        32\n",
      "       happy       0.55      0.53      0.54        34\n",
      "     neutral       0.45      0.25      0.32        20\n",
      "         sad       0.50      0.41      0.45        39\n",
      "   surprised       0.43      0.36      0.39        45\n",
      "\n",
      "    accuracy                           0.52       288\n",
      "   macro avg       0.51      0.50      0.50       288\n",
      "weighted avg       0.52      0.52      0.51       288\n",
      "\n",
      "Model trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "audio_dir = 'C:/Users/raada/Documents/Pray&Hope/data/audio'\n",
    "X = np.load(os.path.join(audio_dir, 'x.npy'))\n",
    "y = np.load(os.path.join(audio_dir, 'y.npy'))\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train a model( Random Forest Classifier)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#evaluate the model\n",
    "y_pred =model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "dump_dir = 'C:/Users/raada/Documents/Pray&Hope/models'\n",
    "joblib.dump(model, os.path.join(dump_dir, 'audio_emotion_model.pkl'))\n",
    "print(\"Model trained and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e04918",
   "metadata": {},
   "source": [
    "#Predict_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47dd7a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotion: fearful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "model = joblib.load('C:/Users/raada/Documents/Pray&Hope/models/audio_emotion_model.pkl')\n",
    "#path to the new audio file\n",
    "audio_file =  'C:/Users/raada/Documents/Pray&Hope/data/predict_test/03-01-06-01-02-01-01.wav'\n",
    "\n",
    "y, sr =librosa.load(audio_file, sr=16000)  # load and resample the audio file\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "mfccs_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "X_new = mfccs_mean.reshape(1, -1)  # reshape for prediction\n",
    "emotion = model.predict(X_new)\n",
    "\n",
    "print(f'Predicted emotion: {emotion[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
