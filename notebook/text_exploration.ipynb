{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b50c4f",
   "metadata": {},
   "source": [
    "#Text_Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c6d9015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  emotion\n",
      "0                            i didnt feel humiliated  sadness\n",
      "1  i can go from feeling so hopeless to so damned...  sadness\n",
      "2   im grabbing a minute to post i feel greedy wrong    anger\n",
      "3  i am ever feeling nostalgic about the fireplac...     love\n",
      "4                               i am feeling grouchy    anger\n",
      "shape\n",
      "(16000, 2)\n",
      "column\n",
      "Index(['text', 'emotion'], dtype='object')\n",
      "Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     16000 non-null  object\n",
      " 1   emotion  16000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 250.1+ KB\n",
      "None\n",
      "emotion\n",
      "joy         5362\n",
      "sadness     4666\n",
      "anger       2159\n",
      "fear        1937\n",
      "love        1304\n",
      "surprise     572\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "file_path ='../data/text/training.csv'  # Adjust path if needed\n",
    "df = pd.read_csv(file_path)  # Adjust path if needed\n",
    "\n",
    "# Show the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# Check the number of rows and columns\n",
    "print(\"shape\")\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# View column names\n",
    "print(\"column\")\n",
    "print(df.columns)\n",
    "\n",
    "# See a summary of the data\n",
    "print(\"Info\")\n",
    "print(df.info())\n",
    "\n",
    "# Check the distribution of emotion labels\n",
    "print(df['emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5245aa",
   "metadata": {},
   "source": [
    "#preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3930bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\raada\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\raada\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\raada\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import string\n",
    "\n",
    "# Download NLTK data (if not already downloaded)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e084eacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0                            i didnt feel humiliated   \n",
      "1  i can go from feeling so hopeless to so damned...   \n",
      "2   im grabbing a minute to post i feel greedy wrong   \n",
      "3  i am ever feeling nostalgic about the fireplac...   \n",
      "4                               i am feeling grouchy   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0                              didnt feel humiliated  \n",
      "1  go feeling hopeless damned hopeful around some...  \n",
      "2          im grabbing minute post feel greedy wrong  \n",
      "3  ever feeling nostalgic fireplace know still pr...  \n",
      "4                                    feeling grouchy  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the training data\n",
    "file_path ='../data/text/training.csv'  # Adjust path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(df[['text', 'cleaned_text']].head())\n",
    "\n",
    "# Save preprocessed data for use in other scripts\n",
    "df.to_csv('../data/text/cleaned_training.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4babd",
   "metadata": {},
   "source": [
    "#train_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a3f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the preprocessed data\n",
    "df = pd.read_csv('../data/text/cleaned_training.csv')\n",
    "\n",
    "# Convert text to numerical features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "y = df['emotion']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7881e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4945260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.90      0.80      0.85       427\n",
      "        fear       0.86      0.74      0.80       397\n",
      "         joy       0.79      0.96      0.87      1021\n",
      "        love       0.89      0.56      0.69       296\n",
      "     sadness       0.89      0.94      0.91       946\n",
      "    surprise       0.88      0.44      0.59       113\n",
      "\n",
      "    accuracy                           0.85      3200\n",
      "   macro avg       0.87      0.74      0.78      3200\n",
      "weighted avg       0.86      0.85      0.84      3200\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.93      0.27      0.42       427\n",
      "        fear       0.92      0.21      0.34       397\n",
      "         joy       0.59      0.99      0.74      1021\n",
      "        love       1.00      0.02      0.04       296\n",
      "     sadness       0.70      0.93      0.80       946\n",
      "    surprise       0.00      0.00      0.00       113\n",
      "\n",
      "    accuracy                           0.66      3200\n",
      "   macro avg       0.69      0.40      0.39      3200\n",
      "weighted avg       0.72      0.66      0.57      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raada\\Documents\\Pray&Hope\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\raada\\Documents\\Pray&Hope\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\raada\\Documents\\Pray&Hope\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#train Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4c9f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/text_vectorizer.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "best_model = lr_model\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, '../models/text_emotion_model.pkl')\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, '../models/text_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8c11b",
   "metadata": {},
   "source": [
    "#main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d40a5da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sadness']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load('../models/text_emotion_model.pkl')\n",
    "vectorizer = joblib.load('../models/text_vectorizer.pkl')  \n",
    "\n",
    "new_text = \"Its a sad sad day\"\n",
    "cleaned_text = preprocess_text(new_text)\n",
    "X_new = vectorizer.transform([cleaned_text])\n",
    "prediction = model.predict(X_new)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
